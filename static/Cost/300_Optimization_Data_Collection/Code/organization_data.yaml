---
AWSTemplateFormatVersion: '2010-09-09'
Description: Lambda to collect Org data and store in S3 
Parameters:
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket that is created to hold org data
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  ManagementAccountRole:
    Type: String
    Description:  ARN of the IAM role deployed in the management accounts which can retrieve lambda data.
  DatabaseName:
    Type: String
    Description: Athena Database name where you table will be created
    Default: optimization_data
  GlueRoleARN:
    Type: String
  RolePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  Schedule:
    Type: String
    Description: Cron job to trigger the lambda using cloudwatch event
    Default: "rate(14 days)"
Outputs:
  LambdaFunctionName:
    Value:
      Ref: LambdaOrgData
  LambdaFunctionARN:
    Description: Lambda function ARN.
    Value:
      Fn::GetAtt:
        - LambdaOrgData
        - Arn
Resources:
  LambdaOrgData:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub
        - 'Lambda_Organization_Data_${Id}'
        - Id: !Select [0, !Split ['-', !Ref AWS::StackName]]
      Description: LambdaFunction of python3.8.
      Runtime: python3.8
      Code:
        ZipFile: |
          #!/usr/bin/env python3
          #Gets org data, grouped by ous and tags from management accounts in json
          #Author Stephanie Gooch 2020
          import boto3
          import logging
          from botocore.exceptions import ClientError
          from botocore.client import Config
          import os
          import datetime
          import json

          def timeconverter(o):
              if isinstance(o, datetime.datetime):
                  return o.__str__()
              
          def lambda_handler(event, context):
              management_role_arn = os.environ["MANAGMENTARN"]
              sts_connection = boto3.client('sts')
              acct_b = sts_connection.assume_role(
                  RoleArn=management_role_arn,
                  RoleSessionName="cross_acct_lambda"
              )
              ACCESS_KEY = acct_b['Credentials']['AccessKeyId']
              SECRET_KEY = acct_b['Credentials']['SecretAccessKey']
              SESSION_TOKEN = acct_b['Credentials']['SessionToken']
              client = boto3.client(
                  "organizations", region_name="us-east-1", #Using the Organizations client to get the data. This MUST be us-east-1 regardless of region you have the Lamda in
                  aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY, aws_session_token=SESSION_TOKEN, )

              root_id    = client.list_roots()['Roots'][0]['Id']
              ou_id_list = get_ou_ids(root_id, client)
              with open('/tmp/ou-org.json', 'w') as f:
                  for ou in ou_id_list.keys():
                      account_data(f, ou, ou_id_list[ou][0], client, ou_id_list[ou][1])
              s3_upload('ou-org')

              with open('/tmp/acc-org.json', 'w') as f:
                  account_data(f, root_id, root_id, client,'')
              s3_upload('acc-org')
              start_crawler(os.environ["CRAWLER"])

          def get_ou_ids(parent_id, client):
              full_result = {}
              test = []
              ous = ou_loop(parent_id, test, client)
              print(ous)
              
              for ou in ous:
                  ou_info = client.describe_organizational_unit(OrganizationalUnitId=ou)
                  full_result[ou]=[]
                  full_result[ou].append(ou_info['OrganizationalUnit']['Name'])
                  tags =list_tags(client, ou)
                  full_result[ou].append(tags)
              return full_result

          def ou_loop(parent_id, test, client):
              print(parent_id)
              paginator = client.get_paginator('list_children')
              iterator = paginator.paginate( ParentId=parent_id, ChildType='ORGANIZATIONAL_UNIT')
              for page in iterator:
                  for ou in page['Children']:
                      test.append(ou['Id'])
                      ou_loop(ou['Id'], test, client)
              return test

          def account_data(f, parent, parent_name, client, parent_tags):
              account_id_list = get_acc_ids(parent, client)
              for account_id in account_id_list:
                  response = client.describe_account(AccountId=account_id)
                  account  = response["Account"]          
                  tags_list = list_tags(client, account["Id"])
                  for org_tag in tags_list:
                      tag = org_tag['Key']
                      value = org_tag['Value']
                      kv = {tag : value}
                      account.update(kv)
                  account.update({'Parent' : parent_name, 'Parent_Tags':parent_tags})        
                  data = json.dumps(account, default = timeconverter) 
                  f.write(data)
                  f.write('\n')
                  

          def get_acc_ids(parent_id,  client):
              full_result = []
              paginator = client.get_paginator('list_accounts_for_parent')
              iterator  = paginator.paginate(ParentId=parent_id)
              for page in iterator:
                  for acc in page['Accounts']:
                      print(acc['Id'])
                      full_result.append(acc['Id'])
              return full_result

          def list_tags(client, resource_id): 
              tags = []
              paginator = client.get_paginator("list_tags_for_resource")
              response_iterator = paginator.paginate(ResourceId=resource_id)
              for response in response_iterator:
                  tags.extend(response['Tags'])
              return tags

          def s3_upload(file_name):
              bucket = os.environ["BUCKET_NAME"] 
              try:
                  s3 = boto3.client('s3', os.environ["REGION"],config=Config(s3={'addressing_style': 'path'}))
                  s3.upload_file(f'/tmp/{file_name}.json', bucket, f"organisation-data/{file_name}.json") 
                  print(f"{file_name}org data in s3")
              except Exception as e:
                  print(e)

          def start_crawler(Crawler_Name):
              glue_client = boto3.client("glue")
              try:
                  glue_client.start_crawler(Name=Crawler_Name)
                  print(f"{Crawler_Name} has been started")
              except Exception as e:
                  # Send some context about this error to Lambda Logs
                  logging.warning("%s" % e)

      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 600
      Role: 
        Fn::GetAtt:
          - LambdaRole
          - Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          REGION: !Ref "AWS::Region"
          MANAGMENTARN: !Ref ManagementAccountRole
          CRAWLER: !Ref OrgCrawler
  OrgCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name:  !Join
          - '-'
          - - 'OrgGlueCrawler'
            - !Select [0, !Split ['-', !Ref AWS::StackName]]
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/organisation-data/"
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${RolePrefix}AWS-Organization-Data-Execute-Lambda"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute
      Path: /
      Policies:
        - PolicyName: "Assume-Management-Organization-Data-Role"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource:
                  Ref: ManagementAccountRole
        - PolicyName: "S3-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                  - "logs:DescribeLogStreams"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/Lambda_Organization_Data_Collector*"
              - Effect: "Allow"
                Action:
                  - "glue:StartCrawler"
                Resource: !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:crawler/${OrgCrawler}"
  CloudWatchTrigger:
    Type: AWS::Events::Rule
    Properties:
      Description: Monthly
      Name: Monthly-Scheduler-For-Accounts
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      Targets:
        - Arn:
            Fn::GetAtt:
              - LambdaOrgData
              - Arn
          Id: WeeklyTriggerForGetAccounts
  EventPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt LambdaOrgData.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt CloudWatchTrigger.Arn
  AthenaQuery:
      Type: AWS::Athena::NamedQuery
      Properties:
        Database: optimization_data
        Description: Provides a summary view of the budgets
        Name: org_cur
        QueryString:  
          CREATE OR REPLACE VIEW org_cur AS
          SELECT *
          FROM ("managementcur"."cur" cur
          INNER JOIN "managementcur"."organisation_data"
            ON ("cur"."line_item_usage_account_id" = "organisation_data"."id")) 
